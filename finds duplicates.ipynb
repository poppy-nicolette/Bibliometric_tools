{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1fGXwl_zIrN9dzcCYXuiPtS4a7uFCryEa","authorship_tag":"ABX9TyMwYuOHMrAG3TnV4vPbDicj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# checks for matches between issns"],"metadata":{"id":"03OfP_AY8yLc"}},{"cell_type":"code","source":["import requests\n","import pandas as pd\n","\n","def fetch_dois_by_issn(issn):\n","    api_url = f'https://api.crossref.org/journals/{issn}/works'\n","    response = requests.get(api_url)\n","\n","    if response.status_code == 200:\n","        data = response.json()\n","        return data.get('message', {}).get('items', [])\n","    else:\n","        print(f\"Error fetching DOIs for ISSN {issn}. Status code: {response.status_code}\")\n","        return []\n","\n","def create_dataframe(dois):\n","    rows = []\n","\n","    for doi in dois:\n","        title = doi.get('title', [''])[0]\n","        journal_title = doi.get('container-title', [''])[0]\n","        publication_year = doi.get('published-print', {}).get('date-parts', [[None]])[0][0]\n","\n","        rows.append({'DOI': doi['DOI'], 'Title': title, 'Journal Title': journal_title, 'Publication Year': publication_year})\n","\n","    return pd.DataFrame(rows)\n","\n","def find_duplicates(df):\n","    duplicates = df[df.duplicated(subset=['Title', 'Journal Title', 'Publication Year'], keep=False)]\n","    return duplicates\n","\n","def main(issn1, issn2):\n","    # Replace these with your actual ISSNs\n","    #issn1 = '1234-5678'\n","    #issn2 = '9876-5432'\n","\n","    # Fetch DOIs for the given ISSNs\n","    dois_issn1 = fetch_dois_by_issn(issn1)\n","    dois_issn2 = fetch_dois_by_issn(issn2)\n","\n","    # Create dataframes for each ISSN\n","    df1 = create_dataframe(dois_issn1)\n","    df2 = create_dataframe(dois_issn2)\n","\n","    # Merge dataframes on common columns (DOI, Title, Journal Title, Publication Year)\n","    merged_df = pd.merge(df1, df2, on=['Title', 'Journal Title', 'Publication Year'], how='inner', suffixes=('_issn1', '_issn2'))\n","\n","    # Find and display duplicates\n","    duplicates = find_duplicates(merged_df)\n","    print(\"Duplicates based on matching Title, Journal Title, and Publication Year:\")\n","    print(duplicates)\n","\n","\n"],"metadata":{"id":"Ik04Bqo272Xl","executionInfo":{"status":"ok","timestamp":1704899627344,"user_tz":240,"elapsed":170,"user":{"displayName":"Poppy Nicolette","userId":"00233107180941394083"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["main()"],"metadata":{"id":"SJaUisYL782Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install fuzzywuzzy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5K8ZucaNBpX_","executionInfo":{"status":"ok","timestamp":1704901138756,"user_tz":240,"elapsed":7598,"user":{"displayName":"Poppy Nicolette","userId":"00233107180941394083"}},"outputId":"de6e33b8-d57b-414b-f8ac-bf36ac9cb735"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fuzzywuzzy\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0\n"]}]},{"cell_type":"code","source":["import requests\n","import pandas as pd\n","from fuzzywuzzy import fuzz\n","\n","def fetch_metadata_by_issn(issn):\n","    api_url = f'https://api.crossref.org/works?filter=issn:{issn}&select=DOI,title,container-title,issued'\n","    response = requests.get(api_url)\n","\n","    if response.status_code == 200:\n","        data = response.json()\n","        return data.get('message', {}).get('items', [])\n","    else:\n","        print(f\"Error fetching metadata for ISSN {issn}. Status code: {response.status_code}\")\n","        return []\n","\n","def create_dataframe(metadata):\n","    rows = []\n","\n","    for entry in metadata:\n","        doi = entry.get('DOI', '')\n","        title = entry.get('title', '')\n","        journal_title = entry.get('container-title', [''])[0]\n","        publication_date = entry.get('issued', {}).get('date-parts', [[None]])[0][0]\n","\n","        rows.append({'DOI': doi, 'Title': title, 'Journal Title': journal_title, 'Publication Date': publication_date})\n","\n","    return pd.DataFrame(rows)\n","\n","def find_duplicates(df):\n","    df['Title Cleaned'] = df['Title'].apply(lambda x: x[0].lower() if x and pd.notna(x[0]) else x)\n","\n","    # Use the fuzzywuzzy library to calculate Levenshtein distance\n","    df['Levenshtein Ratio'] = df.groupby('Journal Title')['Title Cleaned'].apply(lambda x: x.apply(lambda y: fuzz.ratio(x.iloc[0], y) if pd.notna(x.iloc[0]) else 0))\n","\n","    # You can adjust the threshold as needed\n","    duplicates = df[df['Levenshtein Ratio'] > 50]  # Change 90 to the desired threshold\n","\n","    return duplicates\n","\n","def main(issn):\n","    # Replace this with your actual ISSN\n","    #issn = '1875-6883'\n","\n","    # Fetch metadata for the given ISSN\n","    metadata = fetch_metadata_by_issn(issn)\n","\n","    # Create dataframe\n","    df = create_dataframe(metadata)\n","\n","    # Find and display duplicates based on Levenshtein distance\n","    duplicates = find_duplicates(df)\n","    print(\"Duplicates based on Levenshtein distance in titles:\")\n","    print(duplicates)\n","\n","\n"],"metadata":{"id":"yyBBSnryBIwB","executionInfo":{"status":"ok","timestamp":1704902979526,"user_tz":240,"elapsed":172,"user":{"displayName":"Poppy Nicolette","userId":"00233107180941394083"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["issn = \"18756883\"\n","main(issn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czL6LaCoBUOe","executionInfo":{"status":"ok","timestamp":1704902985946,"user_tz":240,"elapsed":2837,"user":{"displayName":"Poppy Nicolette","userId":"00233107180941394083"}},"outputId":"8ba9a776-4c00-4350-ae2c-a44c0efeae38"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Duplicates based on Levenshtein distance in titles:\n","                            DOI  \\\n","0  10.1080/18756891.2013.865403   \n","\n","                                               Title  \\\n","0  [A New Adaptive and Self Organizing Fuzzy Poli...   \n","\n","                                       Journal Title  Publication Date  \\\n","0  International Journal of Computational Intelli...              2014   \n","\n","                                       Title Cleaned  Levenshtein Ratio  \n","0  a new adaptive and self organizing fuzzy polic...                100  \n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-37-fc85d4014cdb>:33: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n","To preserve the previous behavior, use\n","\n","\t>>> .groupby(..., group_keys=False)\n","\n","To adopt the future behavior and silence this warning, use \n","\n","\t>>> .groupby(..., group_keys=True)\n","  df['Levenshtein Ratio'] = df.groupby('Journal Title')['Title Cleaned'].apply(lambda x: x.apply(lambda y: fuzz.ratio(x.iloc[0], y) if pd.notna(x.iloc[0]) else 0))\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from fuzzywuzzy import fuzz\n","import re\n","\n","def read_excel_file(file_path):\n","    # Read data from Excel file\n","    df = pd.read_excel(file_path)\n","    return df\n","\n","def clean_title(title):\n","    # Remove specific characters and square brackets and their contents\n","    if isinstance(title, str):\n","        title = re.sub(r'\\[[^\\]]*\\]', '', title)\n","        title = re.sub('[^a-zA-Z0-9\\s]', '', title)\n","    elif isinstance(title, list):\n","        # Join the list elements into a string\n","        title = ' '.join(map(str, title))\n","        title = re.sub(r'\\[[^\\]]*\\]', '', title)\n","        title = re.sub('[^a-zA-Z0-9\\s]', '', title)\n","    return title\n","\n","def create_dataframe(df):\n","    rows = []\n","\n","    for index, row in df.iterrows():\n","        doi = row.get('DOI', '')  # Adjust column name based on your Excel file\n","        title = row.get('title', '')  # Adjust column name based on your Excel file\n","        title = clean_title(title)  # Clean the title\n","        journal_title = row.get('container-title', '')  # Adjust column name based on your Excel file\n","        publication_date = row.get('issued', None)  # Adjust column name based on your Excel file\n","\n","        rows.append({'DOI': doi, 'Title': title, 'Journal Title': journal_title, 'Publication Date': publication_date})\n","\n","    return pd.DataFrame(rows)\n","\n","def find_duplicates(df):\n","    df['Title Cleaned'] = df['Title'].apply(lambda x: x[0].lower() if isinstance(x, list) and x and pd.notna(x[0]) else x)\n","\n","    # Use the fuzzywuzzy library to calculate Levenshtein distance\n","    df['Levenshtein Ratio'] = df.groupby('Journal Title', group_keys=False)['Title Cleaned'].apply(lambda x: x.apply(lambda y: fuzz.ratio(x.iloc[0], y[0]) if isinstance(x.iloc[0], list) and pd.notna(x.iloc[0]) else 0))\n","\n","    # You can adjust the threshold as needed\n","    duplicates = df[df['Levenshtein Ratio'] > 20]  # Change 90 to the desired threshold\n","\n","    return duplicates\n","\n","def main(file_path):\n","    # Read data from Excel file\n","    df = read_excel_file(file_path)\n","\n","    # Create dataframe\n","    df_cleaned = create_dataframe(df)\n","\n","    # Find and display duplicates based on Levenshtein distance\n","    duplicates = find_duplicates(df_cleaned)\n","    print(\"Duplicates based on Levenshtein distance in titles:\")\n","    print(duplicates)\n","\n","# Replace 'your_excel_file.xlsx' with the path to your Excel file\n","excel_file_path = '/content/drive/MyDrive/Colab Notebooks/Crossref_notebooks/all_titles_for_ISSN_18756883.xlsx'\n","main(excel_file_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2_VU0UBIpDw","executionInfo":{"status":"ok","timestamp":1704903123206,"user_tz":240,"elapsed":1047,"user":{"displayName":"Poppy Nicolette","userId":"00233107180941394083"}},"outputId":"fec38384-9e83-413b-e558-8eb9758102d5"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Duplicates based on Levenshtein distance in titles:\n","Empty DataFrame\n","Columns: [DOI, Title, Journal Title, Publication Date, Title Cleaned, Levenshtein Ratio]\n","Index: []\n"]}]},{"cell_type":"markdown","source":["This works and saves out an excel fie."],"metadata":{"id":"iKqbAOSHYlZ2"}},{"cell_type":"code","source":["import pandas as pd\n","\n","def read_excel_file(file_path):\n","    # Read data from Excel file\n","    df = pd.read_excel(file_path)\n","    return df\n","\n","def clean_title(title):\n","    # Remove specific characters and square brackets and their contents\n","    if isinstance(title, str):\n","        title = re.sub(r'\\[[^\\]]*\\]', '', title)\n","        title = re.sub('[^a-zA-Z0-9\\s]', '', title)\n","    elif isinstance(title, list):\n","        # Join the list elements into a string\n","        title = ' '.join(map(str, title))\n","        title = re.sub(r'\\[[^\\]]*\\]', '', title)\n","        title = re.sub('[^a-zA-Z0-9\\s]', '', title)\n","    return title\n","\n","def create_dataframe(df):\n","    rows = []\n","\n","    for index, row in df.iterrows():\n","        doi = row.get('DOI', '')  # Adjust column name based on your Excel file\n","        title = row.get('title', '')  # Adjust column name based on your Excel file\n","        title = clean_title(title)  # Clean the title\n","        journal_title = row.get('container-title', '')  # Adjust column name based on your Excel file\n","        publication_date = row.get('issued', None)  # Adjust column name based on your Excel file\n","\n","        rows.append({'DOI': doi, 'Title': title, 'Journal Title': journal_title, 'Publication Date': publication_date})\n","\n","    return pd.DataFrame(rows)\n","\n","def find_duplicates(df):\n","    duplicates = df[df.duplicated(subset=['Title'], keep=False)]\n","    return duplicates\n","\n","def save_to_excel(df, file_path):\n","    df.to_excel(file_path, index=False)\n","    print(f\"DataFrame saved to {file_path}\")\n","\n","def main(file_path):\n","    # Read data from Excel file\n","    df = read_excel_file(file_path)\n","\n","    # Create dataframe\n","    df_cleaned = create_dataframe(df)\n","\n","    # Find and display duplicates based on exact title matching\n","    duplicates = find_duplicates(df_cleaned)\n","    print(\"Duplicates based on exact title matching:\")\n","    print(duplicates)\n","\n","    # Save duplicates to a new Excel file\n","    save_to_excel(duplicates, '/content/drive/MyDrive/Colab Notebooks/Crossref_notebooks/duplicates_output.xlsx')\n","\n","# Replace 'your_excel_file.xlsx' with the path to your Excel file\n","excel_file_path = '/content/drive/MyDrive/Colab Notebooks/Crossref_notebooks/all_titles_for_ISSN_18756883.xlsx'\n","main(excel_file_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VsHkM0ItLYDE","executionInfo":{"status":"ok","timestamp":1704903755773,"user_tz":240,"elapsed":939,"user":{"displayName":"Poppy Nicolette","userId":"00233107180941394083"}},"outputId":"bf927f2d-405f-438d-ca56-f7caeda8ea6c"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Duplicates based on exact title matching:\n","                                DOI  \\\n","0           10.2991/jnmp.2008.1.3.1   \n","5          10.2991/ijcis.2010.3.2.7   \n","6     10.1080/18756891.2010.9727690   \n","11    10.1080/18756891.2011.9727879   \n","12        10.2991/ijcis.2011.4.6.22   \n","...                             ...   \n","2110   10.1080/18756891.2014.891369   \n","2111   10.1080/18756891.2014.963976   \n","2112  10.1080/18756891.2011.9727766   \n","2113       10.2991/ijcis.2011.4.1.8   \n","2114   10.1080/18756891.2013.808426   \n","\n","                                                  Title  \\\n","0                                                         \n","5                       A nave glance at Soft Computing   \n","6                       A nave glance at Soft Computing   \n","11    A Calibration Method for A Linear Structured L...   \n","12    A Calibration Method for A Linear Structured L...   \n","...                                                 ...   \n","2110                                                      \n","2111                                                      \n","2112                                                      \n","2113                                                      \n","2114                                                      \n","\n","                                          Journal Title Publication Date  \n","0     International Journal of Computational Intelli...             2008  \n","5     International Journal of Computational Intelli...             2010  \n","6     International Journal of Computational Intelli...          2010, 6  \n","11    International Journal of Computational Intelli...         2011, 12  \n","12    International Journal of Computational Intelli...             2011  \n","...                                                 ...              ...  \n","2110  International Journal of Computational Intelli...             2014  \n","2111  International Journal of Computational Intelli...             2014  \n","2112  International Journal of Computational Intelli...          2011, 2  \n","2113  International Journal of Computational Intelli...             2011  \n","2114  International Journal of Computational Intelli...             2013  \n","\n","[570 rows x 4 columns]\n","DataFrame saved to /content/drive/MyDrive/Colab Notebooks/Crossref_notebooks/duplicates_output.xlsx\n"]}]}]}