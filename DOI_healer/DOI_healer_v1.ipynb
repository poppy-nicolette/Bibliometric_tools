{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7ff9b7",
   "metadata": {},
   "source": [
    "# DOI healer:\n",
    "find OA versions of DOIs that have bad response codes using the UnPaywall API. <br>\n",
    " [ ] check URL response code - make sure they were bad<br>\n",
    " [ ] check new URL reposnse code - make sure it is good<br>\n",
    " [ ] check CR metadata if there are license elements<br>\n",
    " \t[ ] if license element - flag with new column to sort later or update later. <br>\n",
    "[x] create a new list of DOIs and new URLS to turn into a txt file<br>\n",
    "[x] save this text file with a header<br>\n",
    "    [x] input variables: prefix, email<br>\n",
    "    [ ] check prefix - make sure all the same prefix<br>\n",
    "#### references\n",
    "https://pypi.org/project/unpywall/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2dbf928",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unpywall\n",
      "  Downloading unpywall-0.2.2.tar.gz (15 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/anaconda3/lib/python3.8/site-packages (from unpywall) (1.4.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from unpywall) (2.28.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->unpywall) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->unpywall) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.8/site-packages (from pandas->unpywall) (1.22.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->unpywall) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->unpywall) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->unpywall) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->unpywall) (1.26.12)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->unpywall) (1.16.0)\n",
      "Building wheels for collected packages: unpywall\n",
      "  Building wheel for unpywall (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unpywall: filename=unpywall-0.2.2-py3-none-any.whl size=12260 sha256=58b74fb1ec966a67c4935f9718caadffb1a8074fdda58a8d818fc4dcca5c8552\n",
      "  Stored in directory: /Users/nicolapoppy/Library/Caches/pip/wheels/94/cc/ac/3881a8552614cc8c704349f7661d3a95670ad823ec9f780a89\n",
      "Successfully built unpywall\n",
      "Installing collected packages: unpywall\n",
      "Successfully installed unpywall-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unpywall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b540b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Your email has been set."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unpywall\n",
    "from unpywall.utils import UnpywallCredentials\n",
    "\n",
    "UnpywallCredentials('pnriddle@dal.ca')\n",
    "\n",
    "from unpywall import Unpywall\n",
    "\n",
    "# Set your email for Unpaywall authorization\n",
    "unpywall.utils.UnpywallCredentials('pnriddle@dal.ca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72ff8f",
   "metadata": {},
   "source": [
    "## This works for passing a short list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be3fd0ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI: 10.1016/j.artmed.2024.102780 - PDF URL: None\n",
      "DOI: 10.1038/nature12373 - PDF URL: https://dash.harvard.edu/bitstream/1/12285462/1/Nanometer-Scale%20Thermometry.pdf\n",
      "DOI: 10.1093/nar/gkr1047 - PDF URL: https://academic.oup.com/nar/article-pdf/40/D1/D1211/9475831/gkr1047.pdf\n"
     ]
    }
   ],
   "source": [
    "# Search DOI articles\n",
    "doi_list = ['10.1016/j.artmed.2024.102780', '10.1038/nature12373', '10.1093/nar/gkr1047']\n",
    "\n",
    "# Fetch results from the API\n",
    "results = [Unpywall.get_pdf_link(doi) for doi in doi_list]\n",
    "\n",
    "# Save results to tab-delimited file\n",
    "with open('results.txt', 'w') as file:\n",
    "    file.write(\"\\t\".join(map(str, ['DOI', 'PDF URL'])))\n",
    "    for doi, result in zip(doi_list, results):\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"\\t\".join(map(str, [doi, result])))\n",
    "\n",
    "# Display the URL for a given DOI\n",
    "for doi, result in zip(doi_list, results):\n",
    "    print(f\"DOI: {doi} - PDF URL: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287125e",
   "metadata": {},
   "source": [
    "#### this works for passing a txt file of DOIs\n",
    "[ ] need to get output to match that for URL update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea7408",
   "metadata": {},
   "source": [
    "## the one below saves out as a bulk url update text file\n",
    "[x] if None exists, skip<br>\n",
    "[x] it might be worth comparing results to this method<br>\n",
    "    – static get_doc_link(doi: str) → str<br>\n",
    "        - This function returns a link to the best OA location (not necessarily a PDF).<br>\n",
    "        – Parameters:\tdoi (str) – The DOI of the requested paper.<br>\n",
    "        – Returns:\tThe URL of the best OA location (not necessarily a PDF).<br>\n",
    "        – Return type:\tstr<br>\n",
    "[ ] needs progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93c8ae91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is your email? pnriddle@dal.ca\n",
      "what is your prefix? 10.5555\n",
      "DOI: 10.1093/reseval/rvw007 - URL: https://academic.oup.com/rev/article-pdf/25/4/396/8031155/rvw007.pdf\n",
      "DOI: 10.1371/journal.pone.0127502 - URL: https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0127502&type=printable\n",
      "DOI: 10.1007/s11192-015-1765-5 - URL: https://arxiv.org/pdf/1511.08096\n",
      "DOI: 10.1371/journal.pone.0184601 - URL: https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0184601&type=printable\n",
      "DOI: 10.1162/qss_a_00047 - URL: https://direct.mit.edu/qss/article-pdf/1/2/771/1885906/qss_a_00047.pdf\n"
     ]
    }
   ],
   "source": [
    "import unpywall\n",
    "import json\n",
    "import pandas\n",
    "import os\n",
    "\n",
    "\n",
    "# Load DOIs from file\n",
    "local_file = 'DOIs.txt'\n",
    "doi_list = []\n",
    "\n",
    "if os.path.isfile(local_file):\n",
    "    with open(local_file, 'r') as f:\n",
    "        doi_list = [line.strip() for line in f.readlines()]\n",
    "email = input(\"what is your email? \")\n",
    "prefix = input(\"what is your prefix? \")\n",
    "\n",
    "# Check if there are any DOIs in the list\n",
    "if len(doi_list) > 0:\n",
    "    # Fetch results from the API\n",
    "    results = [Unpywall.get_doc_link(doi) for doi in doi_list]#get_pdf_link\n",
    "    \n",
    "    # Save results to tab-delimited file\n",
    "    with open('results.txt', 'w') as file:\n",
    "        file.write(f\"H: email={email};fromPrefix={prefix}\")\n",
    "        for doi, result in zip(doi_list, results):\n",
    "            if result == None:\n",
    "                pass\n",
    "            else:\n",
    "                file.write(\"\\n\")\n",
    "                file.write(\"\\t\".join(map(str, [doi, result])))\n",
    "            \n",
    "    # Display the URL for a given DOI\n",
    "    for doi, result in zip(doi_list, results):\n",
    "        print(f\"DOI: {doi} - URL: {result}\")\n",
    "else:\n",
    "    print(\"No DOIs found in the file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb86458",
   "metadata": {},
   "source": [
    "### this checks the status code after a new URL is found. \n",
    "[ ] other libraries that check for spam or blacklisted websites?<br>\n",
    "    [ ]  check validators module<br>\n",
    "    [ ] check urllib module<br>\n",
    "[ ] see this conversation: https://groups.google.com/g/unpaywall/c/AbNwXdyWZfE/m/S1etf6qaAQAJ <br>\n",
    "[ ] see this error body>\\<div class=\"error\" id=\"error\"> <br>\n",
    "        \\t[ ] maybe this is consistent that can be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "611a9093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Url is valid\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "uses the validators module to check if a URL is valid. \n",
    "It returns 'True' if the URL is valid and 'False' if it is not.\n",
    "\"\"\"\n",
    "\n",
    "import validators\n",
    "\n",
    "valid = validators.url('https://dash.harvard.edu/bitstream/1/12285462/1/Nanometer-Scale%20Thermometry.pdf')\n",
    "if valid == True:\n",
    "    print(\"Url is valid\")\n",
    "else:\n",
    "    print(\"Invalid url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a40ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "uses the urlparse module to parse a URL and check if both scheme and netloc are present.\n",
    "what does this mean?\n",
    "\"\"\"\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "result = urlparse(\"https://dash.harvard.edu/bitstream/1/12285462/1/Nanometer-Scale%20Thermometry.pdf\")\n",
    "if result.scheme and result.netloc:\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3bc1a0",
   "metadata": {},
   "source": [
    "## looks up license information\n",
    "This works, but doesn't always return information - maybe license info is sparse.<br>\n",
    "see schema here for Unpaywall: https://unpaywall.org/data-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9bb4b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "License: cc-by\n",
      "Version: publishedVersion\n",
      "Best Open-Access Location: https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0127502&type=printable\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def lookup_details(doi):\n",
    "    # Define the API endpoint and parameters\n",
    "    endpoint = \"https://api.unpaywall.org/v2/doi/\" + doi + \"?email=pnriddle@dal.ca\"\n",
    "    params = {\"fields\": \"license,version,best_oa_location\"}\n",
    "\n",
    "    # Make the API request and get the response\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    data = response.json()\n",
    "    #pp.pprint(data)\n",
    "    # Check if the request was successful and the DOI was found\n",
    "    if response.status_code == 200:\n",
    "        # Extract and return the details from the nested JSON structure\n",
    "        license_info = data[\"best_oa_location\"][\"license\"]\n",
    "        version_info = data[\"best_oa_location\"][\"version\"]\n",
    "        best_oa_location = data[\"best_oa_location\"][\"url_for_pdf\"]\n",
    "        \n",
    "        return license_info, version_info, best_oa_location\n",
    "    else:\n",
    "        raise ValueError(\"My Queen, I have failed to retrieve details for the given DOI.\")\n",
    "\n",
    "# Example usage\n",
    "doi = \"10.1371/journal.pone.0127502\"  # Replace with your desired DOI\n",
    "license, version, best_oa = lookup_details(doi)\n",
    "print(\"Success!\")\n",
    "print(\"License:\", license)\n",
    "print(\"Version:\", version)\n",
    "print(\"Best Open-Access Location:\", best_oa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "422b6ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/p7r0rgdj65n65jz1z1ks0gk00000gn/T/ipykernel_6826/2045051311.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"DOI\": doi, \"License\": license, \"Version\": version, \"Best OA Location\": best_oa}, ignore_index=True)\n",
      "/var/folders/6f/p7r0rgdj65n65jz1z1ks0gk00000gn/T/ipykernel_6826/2045051311.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"DOI\": doi, \"License\": license, \"Version\": version, \"Best OA Location\": best_oa}, ignore_index=True)\n",
      "/var/folders/6f/p7r0rgdj65n65jz1z1ks0gk00000gn/T/ipykernel_6826/2045051311.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({\"DOI\": doi, \"License\": license, \"Version\": version, \"Best OA Location\": best_oa}, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>License</th>\n",
       "      <th>Version</th>\n",
       "      <th>Best OA Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1371/journal.pone.0127502</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>publishedVersion</td>\n",
       "      <td>https://journals.plos.org/plosone/article/file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1007/s11192-015-1765-5</td>\n",
       "      <td>None</td>\n",
       "      <td>submittedVersion</td>\n",
       "      <td>https://arxiv.org/pdf/1511.08096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1093/reseval/rvw007</td>\n",
       "      <td>None</td>\n",
       "      <td>publishedVersion</td>\n",
       "      <td>https://academic.oup.com/rev/article-pdf/25/4/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            DOI License           Version  \\\n",
       "0  10.1371/journal.pone.0127502   cc-by  publishedVersion   \n",
       "1     10.1007/s11192-015-1765-5    None  submittedVersion   \n",
       "2        10.1093/reseval/rvw007    None  publishedVersion   \n",
       "\n",
       "                                    Best OA Location  \n",
       "0  https://journals.plos.org/plosone/article/file...  \n",
       "1                   https://arxiv.org/pdf/1511.08096  \n",
       "2  https://academic.oup.com/rev/article-pdf/25/4/...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "another version that works from a list and uses a generator expression.\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def lookup_details(doi):\n",
    "    # Define the API endpoint and parameters\n",
    "    endpoint = \"https://api.unpaywall.org/v2/doi/\" + doi + \"?email=pnriddle@dal.ca\"\n",
    "    params = {\"fields\": \"license,version,best_oa_location\"}\n",
    "\n",
    "    # Make the API request and get the response\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    data = response.json()\n",
    "    #pp.pprint(data)\n",
    "\n",
    "    # Check if the request was successful and the DOI was found\n",
    "    if response.status_code == 200:\n",
    "        # Extract and return the details from the nested JSON structure\n",
    "        license_info = data[\"best_oa_location\"][\"license\"]\n",
    "        version_info = data[\"best_oa_location\"][\"version\"]\n",
    "        best_oa_location = data[\"best_oa_location\"][\"url_for_pdf\"]\n",
    "        \n",
    "        return license_info, version_info, best_oa_location\n",
    "    else:\n",
    "        raise ValueError(\"My Queen, I have failed to retrieve details for the given DOI.\")\n",
    "\n",
    "# list of DOIs\n",
    "\n",
    "\n",
    "# Now you have a list of strings containing each line from the text file\n",
    "\n",
    "DOIs = [\"10.1371/journal.pone.0127502\", \"10.1007/s11192-015-1765-5\", \"10.1093/reseval/rvw007\"]  # List of DOIs\n",
    "\n",
    "# Create a pandas dataframe\n",
    "df = pd.DataFrame(columns=[\"DOI\", \"License\", \"Version\", \"Best OA Location\"])\n",
    "\n",
    "# Iterate through the list of DOIs and retrieve the details\n",
    "for doi in DOIs:\n",
    "    license, version, best_oa = lookup_details(doi)\n",
    "    df = df.append({\"DOI\": doi, \"License\": license, \"Version\": version, \"Best OA Location\": best_oa}, ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
